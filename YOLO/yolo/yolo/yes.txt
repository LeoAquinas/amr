#!/usr/env/bin python3

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
from ultralytics import YOLO

from yolo_msgs.msg import InferenceResult
from yolo_msgs.msg import YoloInference


bridge = CvBridge()

class publisherNode(Node):
    #Main Operating Function
    #This is the parent function which nests the process function listen()
    def __init__(self):
        super().__init__("yolo_publisher")

        #Create pubilshers
        self.yolo_inference = YoloInference()
        print(1)
        
        # Load a model
        self.model = YOLO("yolo11n.pt")  # pretrained YOLO11n model
        self.camera_subscriber()


    def camera_subscriber(self):
         self.subscription = self.create_subscription(
              Image,
              '/camera/image_raw',
              self.subscription_callback,
              10
         )
         self.subscription

         self.yolo_inference_publisher = self.create_publisher(YoloInference, '/inference_data', 1)
         self.yolo_img_publisher = self.create_publisher(Image, '/camera/inference_result', 1)

    def subscription_callback(self, img):
        #  print("In callback")
         try:
            # Convert ROS Image message to OpenCV image
            cv_img = bridge.imgmsg_to_cv2(img, "bgr8")

            # Load YOLO model (make sure the model is loaded only once, not inside the callback)
            if not hasattr(self, 'model'):
                self.model = YOLO("yolo11n.pt")  # Load the pretrained YOLO11n model

            # Run inference on the source
            #FOR NOW USE DEFAULT BUILT IN CV2 SHOW ARGUMENT 1ST
            results = self.model(cv_img, show=True)  # list of Results objects
            # results = self.model(cv_img) 


            self.yolo_inference.img_msg.header.stamp = self.get_clock().now().to_msg()
            self.yolo_inference.img_msg.header.frame_id = 'inference'

            # View results
            # for r in results:
            #     # print(r.boxes)  # print the Boxes object containing the detection bounding boxes
            #     boxes = r.boxes
            #     for box in boxes:
            #         self.inference_result = InferenceResult()
            #         bb = box.xyxy[0].to('cpu').detach().numpy().copy()  # Bounding box coordinates [x1, y1, x2, y2]
            #         label = box.cls  # Class ID
            #         # confidence = box.conf  # Confidence score

            #         #Get label name
            #         self.inference_result.class_name = self.model.names[int(label)]
                    
            #         # Convert coordinates to integers
            #         self.inference_result.bb_top = int(bb[0])
            #         self.inference_result.bb_left = int(bb[1])
            #         self.inference_result.bb_bottom = int(bb[2])
            #         self.inference_result.bb_right = int(bb[3])

            #         #Append inference result to msg list
            #         self.yolo_inference.yolo_inference.append(self.inference_result)
                    # cv2.rectangle(cv_img, 
                    #      (self.inference_result.bb_top, self.inference_result.bb_left),
                    #      (self.inference_result.bb_bottom, self.inference_result.bb_right),
                    #      (255, 255, 0)
                    # )

            img_msg = bridge.cv2_to_imgmsg(cv_img, 'bgr8')

            # self.bridge.cv2_to_imgmsg(cv_img)
            self.yolo_img_publisher.publish(img_msg)
            # self.yolo_inference_publisher.publish(self.yolo_inference)

            # self.yolo_inference.yolo_inference.clear()


            #Load detection
            #Image
            # img_msg = self.bridge.cv2_to_imgmsg(cv_img, "bgr8")
            # img_msg.header.stamp = self.get_clock().now().to_msg()
            # img_msg.header.frame_id = 'camera_link'

            #Publish detection
            # self.yolo_img_publisher.publish(img_msg)

            #         # Optionally, draw the bounding box on the image
            #         color = (0, 255, 0)  # Green color for bounding box
            #         cv2.rectangle(cv_img, (self.bb_top, self.bb_left), (self.bb_bottom, self.bb_right), color, 2)
            #         try:
            #             # Optionally, add the label text (e.g., class name and confidence)
            #             label_text = f"ID: {label}, Conf: {confidence:.2f}"
            #             cv2.putText(cv_img, confidence, (self.bb_top, self.bb_left - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            #         except:
            #             print("No Detections")

            # # Display the image with bounding boxes drawn
            # cv2.imshow("YOLO Object Detection", cv_img)
            # cv2.waitKey(1)  # Wait for 1ms and handle window events

         except:
              print("testing")
            #   pass


def main(args=None):
    rclpy.init(args=args)
    node = publisherNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()
	
			

if __name__ == '__main__':
	main()




        


            